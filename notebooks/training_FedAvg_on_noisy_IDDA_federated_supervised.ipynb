{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"nUCMXXjMBfOk"},"source":["**Mount drive and clone repository**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20790,"status":"ok","timestamp":1686738771733,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"jw5MfQIIBbas","outputId":"83c39776-67c7-462d-cea6-709eac22c702"},"outputs":[],"source":["# Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Clone repository\n","import sys\n","!git clone https://github.com/fgiacome/MLDL23-FL-project.git\n","sys.path.append('./MLDL23-FL-project/')\n","%cd MLDL23-FL-project\n","# !git checkout fed_w_avg"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y5YxjT7bSGaf"},"source":["**Server implementation**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4918,"status":"ok","timestamp":1686738776645,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"GrYoZQdqSBPv"},"outputs":[],"source":["import copy\n","from collections import OrderedDict\n","from utils.stream_metrics import StreamSegMetrics\n","import random\n","import numpy as np\n","import torch\n","\n","\n","class Server:\n","    def __init__(\n","        self,\n","        clients_per_round,\n","        num_rounds,\n","        epochs_per_round,\n","        train_clients,\n","        test_clients,\n","        model,\n","        metrics,\n","        random_state=300890,\n","    ):\n","        self.clients_per_round = clients_per_round\n","        self.num_rounds = num_rounds\n","        self.train_clients = train_clients\n","        self.test_clients = test_clients\n","        self.model = model\n","        self.epochs_per_round = epochs_per_round\n","        # self.metrics = {\n","        #     'Train': StreamSegMetrics(n_classes = 16, name = 'Mean IoU'),\n","        #     'Validation': StreamSegMetrics(n_classes = 16, name = 'Mean IoU'),\n","        #     'Test': StreamSegMetrics(n_classes = 16, name = 'Mean IoU')\n","        # }\n","        # The model parameters are saved to a dict and loaded from\n","        # the same dict when it gets updated\n","        self.model_params_dict = copy.deepcopy(self.model.state_dict())\n","        # The list of client updates in a round. It is a list of tuples\n","        # of the form: (training set size, update)\n","        self.updates = []\n","        ## This line stays commented for now, plan is\n","        ## to call random.seed(...) in the notebook explicitly\n","        ## so as to intuitively restore actually unpredictable behavior\n","        # self.prng = np.random.default_rng(random_state)\n","        self.prng = np.random.default_rng()\n","\n","    def select_clients(self):\n","        \"\"\"\n","        This method selects a random subset of `self.clients_per_round` clients\n","        from the given traning clients, without replacement.\n","        :return: list of clients\n","        \"\"\"\n","        num_clients = min(self.clients_per_round, len(self.train_clients))\n","        return self.prng.choice(self.train_clients, num_clients, replace=False)\n","\n","    def load_model_on_clients(self):\n","        \"\"\"\n","        This function loads the centralized model to the clients at\n","        the beginning of each training / testing round.\n","        \"\"\"\n","        for c in self.test_clients + self.train_clients:\n","            c.model.load_state_dict(self.model_params_dict, strict=False)\n","\n","    def train_round(self, clients):\n","        \"\"\"\n","        This method trains the model with the dataset of the clients.\n","        It handles the training at single round level.\n","        The client updates are saved in the object-level list,\n","        they will be aggregated.\n","        :param clients: list of all the clients to train\n","        \"\"\"\n","        train_loss_miou = {str(c): {} for c in clients}\n","\n","        for i, client in enumerate(clients):\n","            num_samples = client.get_num_samples()\n","\n","            # Train the single client model\n","            loss, miou = client.train(self.epochs_per_round)\n","            train_loss_miou[str(client)][\"Loss\"] = loss\n","            train_loss_miou[str(client)][\"mIoU\"] = miou\n","\n","            # Get model parameters\n","            update = client.generate_update()\n","\n","            # The list of updates is saved at instance level,\n","            # but it is also returned as an independent list after each\n","            # train round.\n","            self.updates.append((num_samples, update))\n","        return train_loss_miou\n","\n","    def aggregate(self):\n","        \"\"\"\n","        This method handles the FedAvg aggregation\n","        :param updates: updates received from the clients\n","        :return: aggregated parameters\n","        \"\"\"\n","        # Here we make the average of the updated weights\n","        total_weight = 0\n","        base = OrderedDict()\n","        for client_samples, client_model in self.updates:\n","            total_weight += client_samples\n","            for key, value in client_model.items():\n","                if key in base:\n","                    base[key] += client_samples * value.type(torch.FloatTensor)\n","                else:\n","                    base[key] = client_samples * value.type(torch.FloatTensor)\n","        # averaged_sol_n = copy.deepcopy(self.model_params_dict)\n","        for key, value in base.items():\n","            if total_weight != 0:\n","                # averaged_sol_n[key] = value.to('cuda') / total_weight\n","                self.model_params_dict[key] = value.to(\"cuda\") / total_weight\n","\n","        # self.model.load_state_dict(averaged_sol_n, strict=False)\n","        self.model.load_state_dict(self.model_params_dict, strict=False)\n","        # self.model_params_dict = copy.deepcopy(self.model.state_dict())\n","        self.updates = []\n","\n","    def train(self):\n","        \"\"\"\n","        This method orchestrates the training the evals and tests at rounds level\n","        :return: list (one elem per round) of dicts (one key per client) of dicts\n","            (loss, miou) of lists (one elem per epoch) of scalars\n","        \"\"\"\n","        orchestra_statistics = []\n","        for r in range(self.num_rounds):\n","            self.load_model_on_clients()\n","            clients = self.select_clients()\n","            train_stats = self.train_round(clients)\n","            self.aggregate()\n","            test_stats = self.test()\n","            orchestra_statistics.append((train_stats, test_stats))\n","        return orchestra_statistics\n","\n","    def eval_train(self):\n","        \"\"\"\n","        This method handles the evaluation on the train clients\n","        :return: dict (one key per client) of dicts (loss, miou) of scalars\n","        \"\"\"\n","        self.load_model_on_clients()\n","        eval_statistics = {str(c): {} for c in self.train_clients}\n","        for c in self.train_clients:\n","            l, m = c.test()\n","            eval_statistics[str(c)][\"Loss\"] = l\n","            eval_statistics[str(c)][\"mIoU\"] = m\n","        return eval_statistics\n","\n","    def test(self):\n","        \"\"\"\n","        This method handles the test on the test clients\n","        :return: dict (one key per client) of dicts (loss, miou) of scalars\n","        \"\"\"\n","        self.load_model_on_clients()\n","        eval_statistics = {str(c): {} for c in self.test_clients}\n","        for c in self.test_clients:\n","            l, m = c.test()\n","            eval_statistics[str(c)][\"Loss\"] = l\n","            eval_statistics[str(c)][\"mIoU\"] = m\n","        return eval_statistics"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"hcJ4LXdSCEK5"},"source":["**Transforms and model importations**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1686738776645,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"kCx47dgW2Vrn"},"outputs":[],"source":["# New transforms\n","import PIL\n","from PIL import Image\n","import numpy as np\n","class DegradeGaussianBlur(object):\n","    \"\"\"\n","    Strongly blur the image\n","    \"\"\"\n","    def __init__(self, radius=5):\n","        self.radius = radius\n","\n","    def __call__(self, img, lbl=None):\n","        blurry = img.filter(PIL.ImageFilter.GaussianBlur(radius=self.radius))\n","        if lbl is not None:\n","            return blurry, lbl\n","        else:\n","            return blurry\n","\n","class DegradeGaussianNoise(object):\n","    \"\"\"\n","    Insert noise in the image\n","    \"\"\"\n","    def __init__(self, sigma=35):\n","        self.sigma = sigma\n","\n","    def __call__(self, img, lbl=None):\n","        np_img = np.array(img)\n","        h = np_img.shape[0]\n","        w = np_img.shape[1]\n","        noise = np.int8(np.random.normal(size=(h,w,1), scale=self.sigma)\n","                        .clip(-128,127))\n","        noisy = np.uint8((noise + np_img).clip(0,255))\n","        noisy_PIL = Image.fromarray(noisy)\n","        if lbl is not None:\n","            return noisy_PIL, lbl\n","        else:\n","            return noisy_PIL\n","\n","class DegradePumpGreen(object):\n","    \"\"\"\n","    Insert noise in the image\n","    \"\"\"\n","    def __init__(self, offset=80, sigma=10):\n","        self.sigma = sigma\n","        self.offset = offset\n","\n","    def __call__(self, img, lbl=None):\n","        np_img = np.array(img)\n","        h = np_img.shape[0]\n","        w = np_img.shape[1]\n","        noise = np.int8((np.random.normal(size=(h,w,1), scale=self.sigma)+self.offset)\n","                        .clip(-128,127))\n","        noise_ch2 = np.pad(noise, ((0,0),(0,0),(1,1)))\n","        noisy = np.uint8((noise_ch2 + np_img).clip(0,255))\n","        noisy_PIL = Image.fromarray(noisy)\n","        if lbl is not None:\n","            return noisy_PIL, lbl\n","        else:\n","            return noisy_PIL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8308,"status":"ok","timestamp":1686738784947,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"NppOwRPZBeHc","outputId":"4fa34413-d075-4ba8-f39e-10f7184acd12"},"outputs":[],"source":["# Importations\n","import main\n","import torch\n","import random\n","from datasets.idda import IDDADataset\n","from models import deeplabv3, mobilenetv2\n","import datasets.ss_transforms as sstr\n","\n","# Fix random seed\n","random.seed(300890)\n","\n","# args for dataset and model importation\n","class args:\n","  dataset = 'idda'\n","  model = 'deeplabv3_mobilenetv2'\n","\n","# Model\n","model = main.model_init(args).cuda()\n","\n","# Transforms\n","train_transforms = sstr.Compose([\n","            sstr.ColorJitter(brightness = (0.55, 1.6), contrast = (0.6, 1.6),\n","                             saturation = (0.5, 1.6), hue = (-0.05, 0.05)),\n","            sstr.RandomRotation(degrees = (-5, 5)),\n","            sstr.PadCenterCrop((925, 1644), fill=255), # this removes the\n","                                                       # rotation margins\n","            sstr.Resize((512, 928)),\n","            sstr.ToTensor(),\n","            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","test_transforms = sstr.Compose([\n","            sstr.Resize((512, 928)),\n","            sstr.ToTensor(),\n","            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","train_transforms_degrade = []\n","train_transforms_degrade.append(sstr.Compose([\n","            sstr.ColorJitter(brightness = (0.55, 1.6), contrast = (0.6, 1.6),\n","                             saturation = (0.5, 1.6), hue = (-0.05, 0.05)),\n","            sstr.RandomRotation(degrees = (-5, 5)),\n","            sstr.PadCenterCrop((925, 1644), fill=255), # this removes the\n","                                                       # rotation margins\n","            sstr.Resize((512, 928)),\n","            DegradeGaussianBlur(),\n","            sstr.ToTensor(),\n","            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ]))\n","train_transforms_degrade.append(sstr.Compose([\n","            sstr.ColorJitter(brightness = (0.55, 1.6), contrast = (0.6, 1.6),\n","                             saturation = (0.5, 1.6), hue = (-0.05, 0.05)),\n","            sstr.RandomRotation(degrees = (-5, 5)),\n","            sstr.PadCenterCrop((925, 1644), fill=255), # this removes the\n","                                                       # rotation margins\n","            sstr.Resize((512, 928)),\n","            DegradeGaussianNoise(),\n","            sstr.ToTensor(),\n","            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ]))\n","train_transforms_degrade.append(sstr.Compose([\n","            sstr.ColorJitter(brightness = (0.55, 1.6), contrast = (0.6, 1.6),\n","                             saturation = (0.5, 1.6), hue = (-0.05, 0.05)),\n","            sstr.RandomRotation(degrees = (-5, 5)),\n","            sstr.PadCenterCrop((925, 1644), fill=255), # this removes the\n","                                                       # rotation margins\n","            sstr.Resize((512, 928)),\n","            DegradePumpGreen(),\n","            sstr.ToTensor(),\n","            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ]))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iy_lmJ0qEqNO"},"source":["**Train, Test Same Dom, Test Diff Dom importations**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1686738784948,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"3mU2WjANBeM3"},"outputs":[],"source":["# Importations\n","import os\n","import json\n","from collections import OrderedDict\n","\n","# Initialization of clients datasets\n","root = 'data/idda'\n","with open(os.path.join(root, 'train.json'), 'r') as f:\n","  clients_dict = json.load(f)\n","\n","# Dict -> datasets\n","train_clients_df = OrderedDict()\n","map_clients_transforms = {18: 0, 19: 0, 20: 1, 21: 1, 22: 2, 23: 2}\n","for i, client_id in enumerate(clients_dict.keys()):\n","  if i < 18:\n","    train_clients_df[client_id] = IDDADataset(root = root, list_samples = clients_dict[client_id],\n","                                             transform = train_transforms, client_name = client_id)\n","  else:\n","    train_clients_df[client_id] = IDDADataset(root = root, list_samples = clients_dict[client_id],\n","                                             transform = train_transforms_degrade[map_clients_transforms[i]], client_name = client_id)\n","train_clients_names = list(train_clients_df.keys())\n","\n","# Test set\n","with open(os.path.join(root, 'test_same_dom.txt'), 'r') as f:\n","    test_same_dom_data = f.read().splitlines()\n","    test_same_dom_df = IDDADataset(root = root, list_samples = test_same_dom_data,\n","                                        transform = test_transforms,\n","                                        client_name='test_same_dom')\n","\n","with open(os.path.join(root, 'test_diff_dom.txt'), 'r') as f:\n","    test_diff_dom_data = f.read().splitlines()\n","    test_diff_dom_df = IDDADataset(root=root, list_samples = test_diff_dom_data,\n","                                        transform = test_transforms,\n","                                        client_name='test_diff_dom')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wnowzzFYF0GC"},"source":["**Combinations**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1686738784949,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"eOnecGj9BePU"},"outputs":[],"source":["# Combinations to test with the format [n_clients_round, n_local_epochs]\n","combinations = {'comb_2_1': [2, 1],\n","                'comb_2_3': [2, 3],\n","                'comb_2_6': [2, 6],\n","                'comb_4_1': [4, 1],\n","                'comb_4_3': [4, 3],\n","                'comb_4_6': [4, 6],\n","                'comb_8_1': [8, 1],\n","                'comb_8_2': [8, 3],\n","                'comb_8_6': [8, 6]}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y7QX9O22HIdj"},"source":["**Test cell**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5627282,"status":"ok","timestamp":1686744412223,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"9ROiefg8BeVO"},"outputs":[],"source":["# Client and Server importations\n","import copy\n","from client import Client\n","\n","# Select combination\n","################################################################################\n","############################## CHOOSE COMB! ####################################\n","################################################################################\n","comb = 'comb_4_6' ##############################################################\n","################################################################################\n","############################## CHOOSE COMB! ####################################\n","################################################################################\n","################################################################################\n","# Comb_dict formats: [<n_clients_round>, <n_local_epochs>] #####################\n","#################### [       0     ,             1       ] #####################\n","################################################################################\n","\n","# Assign combinations\n","clients_per_round = combinations[comb][0]\n","epochs_per_round = combinations[comb][1]\n","\n","# Number of total rounds\n","num_rounds = 20\n","\n","# !!CHOOSE REDUCTION!!\n","# reduction \\in \\{'MeanReduction, HardNegativeMining'\\}\n","reduction = 'MeanReduction'\n","\n","# Clients initializations\n","# - Train clients\n","train_clients = [Client(client_dataset = train_clients_df[name], batch_size = 8,\n","                 model = main.model_init(args).cuda(), dataloader = 'train',\n","                 optimizer = 'Adam', lr = 1e-3, device = 'cuda:0',\n","                 reduction = reduction) for name in train_clients_names]\n","\n","# - Test clients [same_dom, diff_dom]\n","test_clients = [Client(client_dataset = test_same_dom_df, batch_size = 16,\n","                model = main.model_init(args).cuda(), dataloader = 'test',\n","                device = 'cuda:0', reduction = reduction),\n","                Client(client_dataset = test_diff_dom_df, batch_size = 16,\n","                model = main.model_init(args).cuda(), dataloader = 'test',\n","                device = 'cuda:0', reduction = reduction)]\n","\n","# Server initialization\n","server = Server(clients_per_round = clients_per_round, num_rounds = num_rounds,\n","                epochs_per_round = epochs_per_round, train_clients = train_clients,\n","                test_clients = test_clients, model = main.model_init(args).cuda(),\n","                metrics = None, random_state = 300890)\n","\n","# Train server on selected combination\n","results = server.train()\n","eval_res = server.eval_train()\n","# results_eval = server.eval_train()\n","# results_test = server.test()\n","\n","# Cast dict\n","# Results dict format {<round_index>: <results>}\n","results_dict = {round_idx: results[round_idx] for round_idx in range(num_rounds)}\n","results_complete = {\n","      \"Train\" : [r[0] for r in results],\n","      \"Test\" : [r[1] for r in results],\n","      \"Eval\": eval_res\n","  }\n","\n","# Save results\n","# Define file name\n","filename = 'results_' + comb + '.json'\n","path = '/content/drive/MyDrive/mldl-project-2b/Results6/'\n","\n","# Save data on file system (Remember to download it!)\n","with open(path + filename, 'w') as fp:\n","  json.dump(results_complete, fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1686744412229,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"c2TM0hym-vOh"},"outputs":[],"source":["same_dom = [res['test_same_dom']['mIoU']['Mean IoU'] for res in results_complete['Test']]\n","diff_dom = [res['test_diff_dom']['mIoU']['Mean IoU'] for res in results_complete['Test']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"elapsed":726,"status":"ok","timestamp":1686744412919,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"TFpO2lXn-4zi","outputId":"f584a44f-3ff5-4069-c1ad-0623ae800990"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(same_dom, label = 's')\n","plt.plot(diff_dom, label = 'd')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
