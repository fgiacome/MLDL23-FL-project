{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"mFEp1V5RlrcK"},"source":["**IMPORTANTE:** \n","- Il runtime di default è **CPU** per non consumare le ore sulle **GPU**, ricordarsi di cambiarlo;\n","\n","**Collegamento a myDrive per download del dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25222,"status":"ok","timestamp":1685369899164,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"8PN5CgCglhkR","outputId":"26d1a96c-bcf3-470d-961b-d509a83ce3ad"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NaXuHszwnMGj"},"source":["**Clone del repository github**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":919,"status":"ok","timestamp":1685369900075,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"O8evumfrllb6","outputId":"7851d466-272a-4ee2-a3c2-4b3da03b1957"},"outputs":[],"source":["!git clone https://github.com/fgiacome/MLDL23-FL-project.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1685369900076,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"kKNk_DTUlliz","outputId":"e23f09af-8cb8-4265-8b7d-c2818deecf17"},"outputs":[],"source":["import sys\n","sys.path.append('./MLDL23-FL-project/')\n","%cd MLDL23-FL-project"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"hHFbOs70JDLc"},"source":["**Training and test function**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3843,"status":"ok","timestamp":1685369903915,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"sgQkQMdHzMPm"},"outputs":[],"source":["# Useful function for model training and testing\n","# Import Intersect Over Union\n","from utils.stream_metrics import StreamSegMetrics\n","from utils.utils import MeanReduction\n","\n","# Training function\n","def train(net, data_loader, loss_function, optimizer):\n","\n","  # Loop initialization\n","  cumulative_loss = 0\n","  samples = 0\n","  mean_iou = StreamSegMetrics(n_classes = 16, name = 'Mean IoU')\n","  reduction = MeanReduction()\n","\n","  # Set the training mode to the model\n","  net.train()\n","\n","  # Loop over batches\n","  for idx, (X, y) in enumerate(data_loader):\n","\n","    # Send data to GPU\n","    X = X.cuda()\n","    # y = y.long()\n","    y = y.cuda()\n","\n","    # Predictions\n","    y_hat = net(X)['out']\n","    y_pred = torch.argmax(y_hat, dim=1)\n","\n","    # Compute loss\n","    criterion = loss_function(y_hat, y)\n","    loss = reduction(criterion, y)\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    # Update training variables\n","    cumulative_loss += loss.item() \n","    samples += X.size(0)\n","    mean_iou.update(y.cpu().numpy(), y_pred.cpu().numpy())\n","\n","  return cumulative_loss / samples, mean_iou.get_results()\n","\n","\n","\n","# Test function\n","def test(net, data_loader, loss_function):\n","\n","  # Test variables initialization\n","  cumulative_loss = 0\n","  samples = 0\n","  mean_iou = StreamSegMetrics(n_classes = 16, name = 'Mean IoU')\n","  reduction = MeanReduction()\n","\n","  # Set the evaluation mode to the model\n","  net.eval()\n","\n","  # Test loop (we don't want to compute the gradients)\n","  with torch.no_grad():\n","\n","    # Loop over batches\n","    for idx, (X, y) in enumerate(data_loader):\n","\n","      # Send data to the GPU\n","      X = X.cuda()\n","      # y = y.long()\n","      y = y.cuda()\n","\n","      # Compute predictions\n","      y_hat = net(X)['out']\n","      y_pred = torch.argmax(y_hat, dim = 1)\n","      \n","      # Loss computation\n","      criterion = loss_function(y_hat, y)\n","      loss = reduction(criterion, y)\n","\n","      # Update test variables\n","      cumulative_loss += loss.item()\n","      samples += X.size(0)\n","      mean_iou.update(y.cpu().numpy(), y_pred.cpu().numpy())\n","\n","  return cumulative_loss / samples, mean_iou.get_results()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yjJF4V7F0DLG"},"source":["**Hyperparams to test**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685369903916,"user":{"displayName":"Alessandro Licciardi","userId":"05864021108147512422"},"user_tz":-120},"id":"Yb6YwVgV0DZU"},"outputs":[],"source":["# Hyperparameters\n","# Parameters lists\n","beta_list = [2e-3, 4e-3, 6e-3]\n","beta_dict = {\n","    2e-3: '2e3',\n","    4e-3: '4e3',\n","    6e-3: '6e3'\n","}\n","\n","# Folder name \n","foldername = 'CP_beta'\n","\n","# Hyperparameters initialization\n","hyperparameters = {\n","    'beta': beta_list[2], # SELECT BETA\n","    'lr': 1e-3    # SELECT BEST LR\n","}\n","\n","# Results path\n","results_path = '/content/drive/MyDrive/mldl-project-2b/FDA_P2_Models_Checkpoints/'\n","foldername = 'CP_beta' + beta_dict[hyperparameters['beta']]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bYXlQfOExrGT"},"source":["**FDA TESTS**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"GRLDUiJYxrRx"},"outputs":[],"source":["# Importations\n","import os\n","import json\n","import main\n","import torch\n","import torch.nn as  nn\n","import random\n","import datasets.ss_transforms as sstr\n","from utils.utils import MeanReduction\n","from datasets.idda import IDDADataset\n","from datasets.GTA import GTADataset\n","from models import deeplabv3, mobilenetv2\n","\n","# Fix random seed\n","random.seed(300890)\n","\n","# args for dataset and model importation\n","class args:\n","  dataset = 'idda'\n","  model = 'deeplabv3_mobilenetv2'\n","\n","# Model\n","model = main.model_init(args).cuda()\n","\n","# First we get raw IDDA dataset     \n","raw_transforms = sstr.Compose([])\n","root = 'data/idda'\n","client_id = \"CENTRALIZED\"\n","with open(os.path.join(root, 'train.json'), 'r') as f:\n","    all_data = json.load(f)\n","idda_img_names = [] \n","for k in all_data.keys():\n","    for i in all_data[k]:\n","      idda_img_names.append(i)\n","\n","# Generate train-validation sets\n","raw_idda_df = IDDADataset(root = root, list_samples = idda_img_names, \n","                            transform = raw_transforms, client_name = client_id)\n","\n","# rFDA initialization\n","rFDA = sstr.RandomFourierDomainAdaptation(beta = hyperparameters['beta'])\n","\n","# Get style from images\n","for i in range(len(raw_idda_df)):\n","  style = rFDA.get_style_from_img(raw_idda_df.__getitem__(i)[0])\n","  rFDA.add_style(style)\n","\n","# GTA Transforms\n","gta_transforms = sstr.Compose([\n","            rFDA,\n","            # sstr.ColorJitter(brightness = (0.55, 1.6), contrast = (0.6, 1.6), \n","            #                  saturation = (0.5, 1.6), hue = (-0.05, 0.05)),\n","            sstr.RandomRotation(degrees = (-5, 5)),\n","            sstr.PadCenterCrop((925, 1644), fill=255), \n","            sstr.Resize((512, 928)), \n","            sstr.ToTensor(),\n","            sstr.Normalize(mean=[0.485, 0.456, 0.406], \n","                            std=[0.229, 0.224, 0.225])\n","        ])\n","\n","# IDDA transforms\n","_, idda_transforms = main.get_transforms(args)\n","\n","# Initialization of train IDDA dataset (centralized)\n","root = 'data/idda'\n","client_id = \"CENTRALIZED\"\n","with open(os.path.join(root, 'train.json'), 'r') as f:\n","    all_data = json.load(f)\n","idda_img_names = [] \n","for k in all_data.keys():\n","    for i in all_data[k]:\n","      idda_img_names.append(i)\n","\n","# Generate train-validation sets\n","idda_df = IDDADataset(root = root, list_samples = idda_img_names, \n","                            transform = idda_transforms, client_name = client_id)\n","  \n","# Initialization of test IDDA dataset\n","with open(os.path.join(root, 'test_same_dom.txt'), 'r') as f:\n","    test_same_dom_data = f.read().splitlines()\n","    test_same_dom_df = IDDADataset(root = root, list_samples = test_same_dom_data, \n","                                        transform = idda_transforms,\n","                                        client_name='test_same_dom')\n","\n","with open(os.path.join(root, 'test_diff_dom.txt'), 'r') as f:\n","    test_diff_dom_data = f.read().splitlines()\n","    test_diff_dom_df = IDDADataset(root = root, list_samples = test_diff_dom_data, \n","                                        transform = idda_transforms,\n","                                        client_name='test_diff_dom')\n","\n","# GTA5 directory\n","root = '/content/drive/MyDrive/MLDL_Datasets/GTA5/'\n","filename = 'train.txt'\n","full_path = root + filename\n","\n","# Import GTA5 images\n","lines_clean = []\n","with open(full_path, 'r') as fp:\n","  lines = fp.readlines()\n","for i, line in enumerate(lines):\n","  if line[-1] == '\\n': \n","    lines[i] = line[:-1]\n","  if os.path.exists(root + '/images/' + lines[i]):\n","    lines_clean.append(lines[i])\n","\n","# GTA5 initialization\n","gta_df = GTADataset(root = root, list_samples = lines_clean,\n","                    transform = gta_transforms, client_name='GTA5')\n","\n","# Data Loaders\n","gta_loader = torch.utils.data.DataLoader(gta_df, \n","                                         batch_size = 8,\n","                                         shuffle = True, num_workers = 2)\n","idda_loader = torch.utils.data.DataLoader(idda_df, batch_size = 16,\n","                                          shuffle = True, num_workers = 2)\n","test_same_dom_loader = torch.utils.data.DataLoader(test_same_dom_df, \n","                                                   batch_size = 16, \n","                                                   shuffle = True, num_workers=2)\n","test_diff_dom_loader = torch.utils.data.DataLoader(test_diff_dom_df, \n","                                                   batch_size = 16,\n","                                                   shuffle=True, num_workers=2)\n","\n","# Criterion\n","criterion = nn.CrossEntropyLoss(ignore_index = 255, reduction = 'none')\n","\n","# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), \n","                             lr = hyperparameters['lr'])\n","\n","# Number of epochs and checkpoint\n","num_epochs = 20\n","checkpoint = 5 # The model is saved every 5 epochs \n","\n","# Initializaion of loss and miou lists for each dataset\n","gta_loss_list = []\n","idda_loss_list = []\n","test_same_dom_loss_list = []\n","test_diff_dom_loss_list = []\n","gta_miou_list = []\n","idda_miou_list = []\n","test_same_dom_miou_list = []\n","test_diff_dom_miou_list = []\n","\n","# Loop on epochs\n","for epoch in range(num_epochs):\n","\n","  # Train the model\n","  gta_loss, gta_miou = train(model, gta_loader, criterion, optimizer)\n","\n","  # Append results\n","  gta_loss_list.append(gta_loss)\n","  gta_miou_list.append(gta_miou)\n","\n","  # Model evaluation\n","  if (epoch + 1) % checkpoint == 0:\n","\n","    checkpoint_path = results_path + foldername + f'/checkpoint_e{epoch + 1}.json'\n","    \n","    # IDDA dataset\n","    idda_loss, idda_miou = test(model, idda_loader, criterion)\n","\n","    # Test datasets\n","    test_same_dom_loss, test_same_dom_miou = test(model, test_same_dom_loader, criterion)\n","    test_diff_dom_loss, test_diff_dom_miou = test(model, test_diff_dom_loader, criterion)\n","\n","    # Append results \n","    idda_loss_list.append(idda_loss)\n","    idda_miou_list.append(idda_miou)\n","    test_same_dom_loss_list.append(test_same_dom_loss)\n","    test_same_dom_miou_list.append(test_same_dom_miou)    \n","    test_diff_dom_loss_list.append(test_diff_dom_loss)\n","    test_diff_dom_miou_list.append(test_diff_dom_miou)    \n","\n","    # Save model \n","    torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'results': {\n","                      'GTA': {\n","                          'Loss': gta_loss,\n","                          'Mean IoU': gta_miou\n","                      },\n","                      'IDDA': {\n","                          'Loss': idda_loss,\n","                          'Mean IoU': idda_miou\n","                      },\n","                      'Test Same Dom': {\n","                          'Loss': test_same_dom_loss,\n","                          'Mean IoU': test_same_dom_miou\n","                      },\n","                      'Test Diff Dom': {\n","                          'Loss': test_diff_dom_loss,\n","                          'Mean IoU': test_diff_dom_miou\n","                      }\n","                  },\n","                }, checkpoint_path)\n","    \n","    print('-----------------------------------------------------')\n","    print(f'\\tEpoch: {epoch + 1}')\n","    print('\\t GTA loss {:.5f}, GTA Mean IoU {:.2f}'.format(gta_loss,\n","          gta_miou['Mean IoU']))\n","    print('\\t IDDA loss {:.5f}, IDDA Mean IoU {:.2f}'.format(idda_loss,\n","          idda_miou['Mean IoU']))\n","    print('\\t Test same dom loss {:.5f}, Test same dom Mean IoU {:.2f}'.format(test_same_dom_loss,\n","          test_same_dom_miou['Mean IoU']))\n","    print('\\t Test diff dom loss {:.5f}, Test diff dom Mean IoU {:.2f}'.format(test_diff_dom_loss,\n","          test_diff_dom_miou['Mean IoU']))\n","    print('-----------------------------------------------------')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z4wEO1Opws_p"},"source":["**Save results**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHgpcINiHBjY"},"outputs":[],"source":["# Import json\n","import json\n","\n","# Path\n","results_path = '/content/drive/MyDrive/mldl-project-2b/FDA_P2_Models_Checkpoints/Results_default/'\n","results_path += foldername\n","results_path += '.json'\n","\n","# Save results on a dict\n","results_dict = {\n","                'GTA': (gta_loss_list, gta_miou_list), \n","                'IDDA': (idda_loss_list, idda_miou_list),\n","                'Test Same Dom': (test_same_dom_loss_list, \n","                                    test_same_dom_miou_list),\n","                'Test Diff Dom': (test_diff_dom_loss_list, \n","                                    test_diff_dom_miou_list)\n","              }\n","\n","# Save data on file system (Remember to download it!)\n","with open(results_path, 'w') as fp:\n","  json.dump(results_dict, fp)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"l7uwdEvcWQ1K"},"source":["- RandomFDA, inizializzare solo con beta;\n","- servono add_style e get_style_from_img \n","\n","chiamata statica\n","RandomFourierDomainAdaptation.get_style_from_img,\n","\n","- l'immagine da passare deve essere PIL (su importazione)\n","- l'immagine da chiamare è dal target dataset (adatto gta sul client)\n","devo ciclare idda dataset e per tutte le immagine devo chiamare get_style_from_img (apri manualmente con open).\n","\n","- salvare np.ndarray in una variabile provvisoria"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
